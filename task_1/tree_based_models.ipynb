{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [{\n",
    "    \"preprocessor__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "    \"preprocessor__min_df\": [2, 4, 7, 10],\n",
    "    \"preprocessor__stop_words\":['english'],\n",
    "    \"model__max_depth\": list(range(3, 7)),\n",
    "    \"model__n_estimators\": [2**i-1 for i in range(3, 7)],\n",
    "    \"model\": [xgb.XGBClassifier()]\n",
    "}, {\n",
    "    \"preprocessor__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "    \"preprocessor__min_df\": [2, 4, 7, 10],\n",
    "    \"preprocessor__stop_words\":['english'],\n",
    "    \"model__max_depth\": list(range(3, 7)),\n",
    "    \"model__n_estimators\": [2**i-1 for i in range(3, 7)],\n",
    "    \"model\": [lgb.LGBMClassifier()]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"preprocessor\", TfidfVectorizer()),\n",
    "    (\"model\", None)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(pipe, grid, n_jobs=-1, cv=3, verbose=2, n_iter=5, scoring=\"f1_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed: 44.1min remaining: 38.6min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 131.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('preprocessor',\n",
       "                                              TfidfVectorizer()),\n",
       "                                             ('model', None)]),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions=[{'model': [XGBClassifier(base_score=None,\n",
       "                                                                 booster=None,\n",
       "                                                                 colsample_bylevel=None,\n",
       "                                                                 colsample_bynode=None,\n",
       "                                                                 colsample_bytree=None,\n",
       "                                                                 gamma=None,\n",
       "                                                                 gpu_id=None,\n",
       "                                                                 importance_type='gain',\n",
       "                                                                 interaction_constraints=None,\n",
       "                                                                 learning_rate...\n",
       "                                         'preprocessor__ngram_range': [(1, 1),\n",
       "                                                                       (1, 2),\n",
       "                                                                       (1, 3)],\n",
       "                                         'preprocessor__stop_words': ['english']},\n",
       "                                        {'model': [LGBMClassifier(max_depth=6,\n",
       "                                                                  n_estimators=63)],\n",
       "                                         'model__max_depth': [3, 4, 5, 6],\n",
       "                                         'model__n_estimators': [7, 15, 31, 63],\n",
       "                                         'preprocessor__min_df': [2, 4, 7, 10],\n",
       "                                         'preprocessor__ngram_range': [(1, 1),\n",
       "                                                                       (1, 2),\n",
       "                                                                       (1, 3)],\n",
       "                                         'preprocessor__stop_words': ['english']}],\n",
       "                   scoring='f1_weighted', verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(data_dict[\"data\"], data_dict[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 TfidfVectorizer(min_df=10, ngram_range=(1, 2),\n",
       "                                 stop_words='english')),\n",
       "                ('model', LGBMClassifier(max_depth=6, n_estimators=63))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8232340073354566"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 TfidfVectorizer(min_df=10, ngram_range=(1, 2),\n",
       "                                 stop_words='english')),\n",
       "                ('model', LGBMClassifier(max_depth=6, n_estimators=63))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = search.best_estimator_\n",
    "est.fit(data_dict['data'], data_dict['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = fetch_20newsgroups(subset=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73       319\n",
      "           1       0.65      0.71      0.68       389\n",
      "           2       0.70      0.72      0.71       394\n",
      "           3       0.61      0.71      0.65       392\n",
      "           4       0.76      0.78      0.77       385\n",
      "           5       0.83      0.68      0.75       395\n",
      "           6       0.85      0.86      0.85       390\n",
      "           7       0.84      0.80      0.82       396\n",
      "           8       0.90      0.86      0.88       398\n",
      "           9       0.89      0.88      0.88       397\n",
      "          10       0.94      0.89      0.92       399\n",
      "          11       0.91      0.83      0.87       396\n",
      "          12       0.49      0.66      0.57       393\n",
      "          13       0.84      0.81      0.83       396\n",
      "          14       0.85      0.86      0.85       394\n",
      "          15       0.84      0.91      0.88       398\n",
      "          16       0.65      0.81      0.72       364\n",
      "          17       0.97      0.77      0.86       376\n",
      "          18       0.69      0.53      0.60       310\n",
      "          19       0.61      0.56      0.59       251\n",
      "\n",
      "    accuracy                           0.77      7532\n",
      "   macro avg       0.78      0.77      0.77      7532\n",
      "weighted avg       0.79      0.77      0.78      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "pred = est.predict(test['data'])\n",
    "print(metrics.classification_report(test['target'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal-rd-course",
   "language": "python",
   "name": "personal-rd-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
