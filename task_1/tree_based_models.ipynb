{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"preprocessor__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "    \"preprocessor__min_df\": [2, 4, 7, 10],\n",
    "    \"preprocessor__stop_words\":['english'],\n",
    "    \"model__max_depth\": list(range(3, 7)),\n",
    "    \"model__n_estimators\": [2**i-1 for i in range(3, 7)],\n",
    "    \"model\": [xgb.XGBClassifier(),\n",
    "              lgb.LGBMClassifier()]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"preprocessor\", TfidfVectorizer()),\n",
    "    (\"model\", None)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(pipe, grid, n_jobs=-1, cv=3, verbose=2, n_iter=10, scoring=\"f1_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  8.3min finished\n",
      "/Users/mykola_yakovliev/.virtualenvs/personal-rd-course/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:22:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('preprocessor',\n",
       "                                              TfidfVectorizer()),\n",
       "                                             ('model', None)]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'model': [XGBClassifier(base_score=None,\n",
       "                                                                booster=None,\n",
       "                                                                colsample_bylevel=None,\n",
       "                                                                colsample_bynode=None,\n",
       "                                                                colsample_bytree=None,\n",
       "                                                                gamma=None,\n",
       "                                                                gpu_id=None,\n",
       "                                                                importance_type='gain',\n",
       "                                                                interaction_constraints=None,\n",
       "                                                                learning_rate=None,\n",
       "                                                                max_...\n",
       "                                                                reg_alpha=None,\n",
       "                                                                reg_lambda=None,\n",
       "                                                                scale_pos_weight=None,\n",
       "                                                                subsample=None,\n",
       "                                                                tree_method=None,\n",
       "                                                                validate_parameters=None,\n",
       "                                                                verbosity=None),\n",
       "                                                  LGBMClassifier()],\n",
       "                                        'model__max_depth': [3, 4, 5, 6],\n",
       "                                        'model__n_estimators': [7, 15, 31, 63],\n",
       "                                        'preprocessor__min_df': [2, 4, 7, 10],\n",
       "                                        'preprocessor__ngram_range': [(1, 1),\n",
       "                                                                      (1, 2),\n",
       "                                                                      (1, 3)],\n",
       "                                        'preprocessor__stop_words': ['english']},\n",
       "                   scoring='f1_weighted', verbose=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(data_dict[\"data\"], data_dict[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([207.48451694,  40.71611762, 249.30416417, 128.75765276,\n",
       "        149.77507027, 169.65733059, 103.56240567, 104.77577734,\n",
       "         74.4770546 ,  26.71790377]),\n",
       " 'std_fit_time': array([ 1.62060967,  0.96014791,  1.49410472, 14.273824  ,  1.91419606,\n",
       "         8.38470854,  1.44150046,  2.11910972,  9.05037262,  5.76454052]),\n",
       " 'mean_score_time': array([8.35808897, 8.73633202, 7.3917222 , 3.58552965, 3.16723641,\n",
       "        2.64488371, 5.28593477, 2.32623235, 1.62092145, 4.2360847 ]),\n",
       " 'std_score_time': array([0.1779599 , 0.24532836, 0.47130644, 0.80671167, 0.3194547 ,\n",
       "        0.28812725, 0.80153457, 0.21021487, 0.09710995, 0.69739189]),\n",
       " 'param_preprocessor__stop_words': masked_array(data=['english', 'english', 'english', 'english', 'english',\n",
       "                    'english', 'english', 'english', 'english', 'english'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocessor__ngram_range': masked_array(data=[(1, 3), (1, 3), (1, 3), (1, 1), (1, 1), (1, 1), (1, 2),\n",
       "                    (1, 1), (1, 2), (1, 3)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_preprocessor__min_df': masked_array(data=[10, 7, 10, 2, 4, 2, 4, 7, 4, 7],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_model__n_estimators': masked_array(data=[31, 15, 31, 15, 31, 15, 15, 31, 7, 7],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_model__max_depth': masked_array(data=[5, 6, 6, 6, 5, 3, 6, 4, 5, 3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_model': masked_array(data=[XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "               gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "               random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "               scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "               validate_parameters=None, verbosity=None),\n",
       "                    LGBMClassifier(),\n",
       "                    XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "               gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "               random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "               scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "               validate_parameters=None, verbosity=None),\n",
       "                    XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "               gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "               random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "               scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "               validate_parameters=None, verbosity=None),\n",
       "                    XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "               gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "               random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "               scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "               validate_parameters=None, verbosity=None),\n",
       "                    LGBMClassifier(),\n",
       "                    XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "               gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "               random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "               scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "               validate_parameters=None, verbosity=None),\n",
       "                    XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "               gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "               random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "               scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "               validate_parameters=None, verbosity=None),\n",
       "                    LGBMClassifier(),\n",
       "                    XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "               gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "               random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "               scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "               validate_parameters=None, verbosity=None)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'preprocessor__stop_words': 'english',\n",
       "   'preprocessor__ngram_range': (1, 3),\n",
       "   'preprocessor__min_df': 10,\n",
       "   'model__n_estimators': 31,\n",
       "   'model__max_depth': 5,\n",
       "   'model': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                 gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                 learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "                 random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "                 scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                 validate_parameters=None, verbosity=None)},\n",
       "  {'preprocessor__stop_words': 'english',\n",
       "   'preprocessor__ngram_range': (1, 3),\n",
       "   'preprocessor__min_df': 7,\n",
       "   'model__n_estimators': 15,\n",
       "   'model__max_depth': 6,\n",
       "   'model': LGBMClassifier()},\n",
       "  {'preprocessor__stop_words': 'english',\n",
       "   'preprocessor__ngram_range': (1, 3),\n",
       "   'preprocessor__min_df': 10,\n",
       "   'model__n_estimators': 31,\n",
       "   'model__max_depth': 6,\n",
       "   'model': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                 gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                 learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "                 random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "                 scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                 validate_parameters=None, verbosity=None)},\n",
       "  {'preprocessor__stop_words': 'english',\n",
       "   'preprocessor__ngram_range': (1, 1),\n",
       "   'preprocessor__min_df': 2,\n",
       "   'model__n_estimators': 15,\n",
       "   'model__max_depth': 6,\n",
       "   'model': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                 gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                 learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "                 random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "                 scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                 validate_parameters=None, verbosity=None)},\n",
       "  {'preprocessor__stop_words': 'english',\n",
       "   'preprocessor__ngram_range': (1, 1),\n",
       "   'preprocessor__min_df': 4,\n",
       "   'model__n_estimators': 31,\n",
       "   'model__max_depth': 5,\n",
       "   'model': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                 gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                 learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "                 random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "                 scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                 validate_parameters=None, verbosity=None)},\n",
       "  {'preprocessor__stop_words': 'english',\n",
       "   'preprocessor__ngram_range': (1, 1),\n",
       "   'preprocessor__min_df': 2,\n",
       "   'model__n_estimators': 15,\n",
       "   'model__max_depth': 3,\n",
       "   'model': LGBMClassifier()},\n",
       "  {'preprocessor__stop_words': 'english',\n",
       "   'preprocessor__ngram_range': (1, 2),\n",
       "   'preprocessor__min_df': 4,\n",
       "   'model__n_estimators': 15,\n",
       "   'model__max_depth': 6,\n",
       "   'model': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                 gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                 learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "                 random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "                 scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                 validate_parameters=None, verbosity=None)},\n",
       "  {'preprocessor__stop_words': 'english',\n",
       "   'preprocessor__ngram_range': (1, 1),\n",
       "   'preprocessor__min_df': 7,\n",
       "   'model__n_estimators': 31,\n",
       "   'model__max_depth': 4,\n",
       "   'model': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                 gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                 learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "                 random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "                 scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                 validate_parameters=None, verbosity=None)},\n",
       "  {'preprocessor__stop_words': 'english',\n",
       "   'preprocessor__ngram_range': (1, 2),\n",
       "   'preprocessor__min_df': 4,\n",
       "   'model__n_estimators': 7,\n",
       "   'model__max_depth': 5,\n",
       "   'model': LGBMClassifier()},\n",
       "  {'preprocessor__stop_words': 'english',\n",
       "   'preprocessor__ngram_range': (1, 3),\n",
       "   'preprocessor__min_df': 7,\n",
       "   'model__n_estimators': 7,\n",
       "   'model__max_depth': 3,\n",
       "   'model': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                 gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                 learning_rate=None, max_delta_step=None, max_depth=5,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=31, n_jobs=None, num_parallel_tree=None,\n",
       "                 random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "                 scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                 validate_parameters=None, verbosity=None)}],\n",
       " 'split0_test_score': array([0.80959911, 0.77990265, 0.80643911, 0.7874723 , 0.8038742 ,\n",
       "        0.75259821, 0.78376085, 0.79768365, 0.75086377, 0.72866903]),\n",
       " 'split1_test_score': array([0.80752888, 0.78783004, 0.8064788 , 0.78476242, 0.81180169,\n",
       "        0.75215738, 0.78569013, 0.80640616, 0.75786289, 0.73520217]),\n",
       " 'split2_test_score': array([0.80188501, 0.78312886, 0.80491987, 0.79161281, 0.80407886,\n",
       "        0.75584398, 0.78621436, 0.80949655, 0.76303892, 0.73501251]),\n",
       " 'mean_test_score': array([0.80633767, 0.78362052, 0.80594593, 0.78794917, 0.80658492,\n",
       "        0.75353319, 0.78522178, 0.80452879, 0.75725519, 0.73296123]),\n",
       " 'std_test_score': array([0.00325996, 0.00325496, 0.00072571, 0.00281692, 0.00368977,\n",
       "        0.00164385, 0.00105497, 0.00500197, 0.00498902, 0.00303604]),\n",
       " 'rank_test_score': array([ 2,  7,  3,  5,  1,  9,  6,  4,  8, 10], dtype=int32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 TfidfVectorizer(min_df=4, stop_words='english')),\n",
       "                ('model',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=5, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=31,\n",
       "                               n_jobs=8, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065849153677007"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:23:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 TfidfVectorizer(min_df=4, stop_words='english')),\n",
       "                ('model',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=5, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=31,\n",
       "                               n_jobs=8, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = search.best_estimator_\n",
    "est.fit(data_dict['data'], data_dict['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = fetch_20newsgroups(subset=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.65      0.69       319\n",
      "           1       0.62      0.67      0.65       389\n",
      "           2       0.68      0.72      0.70       394\n",
      "           3       0.60      0.70      0.65       392\n",
      "           4       0.76      0.77      0.76       385\n",
      "           5       0.77      0.66      0.71       395\n",
      "           6       0.81      0.86      0.84       390\n",
      "           7       0.84      0.78      0.81       396\n",
      "           8       0.89      0.86      0.88       398\n",
      "           9       0.85      0.87      0.86       397\n",
      "          10       0.92      0.87      0.89       399\n",
      "          11       0.90      0.82      0.86       396\n",
      "          12       0.50      0.65      0.56       393\n",
      "          13       0.83      0.76      0.79       396\n",
      "          14       0.84      0.85      0.84       394\n",
      "          15       0.84      0.88      0.86       398\n",
      "          16       0.64      0.77      0.70       364\n",
      "          17       0.95      0.75      0.84       376\n",
      "          18       0.64      0.53      0.58       310\n",
      "          19       0.61      0.55      0.58       251\n",
      "\n",
      "    accuracy                           0.76      7532\n",
      "   macro avg       0.76      0.75      0.75      7532\n",
      "weighted avg       0.77      0.76      0.76      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "pred = est.predict(test['data'])\n",
    "print(metrics.classification_report(test['target'], pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal-rd-course",
   "language": "python",
   "name": "personal-rd-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
