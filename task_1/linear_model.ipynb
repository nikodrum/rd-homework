{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [{\n",
    "    \"preprocessor\": [CountVectorizer()],\n",
    "    \"preprocessor__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "    \"preprocessor__min_df\": [2, 4, 7, 10],\n",
    "    \"preprocessor__stop_words\":['english'],\n",
    "    'model': [LogisticRegression()],\n",
    "    'model__penalty': ['l1', 'l2'],\n",
    "    'model__max_iter': [1000],\n",
    "    'model__C': np.logspace(-4, 4, 10)\n",
    "    }, {\n",
    "    \"preprocessor\": [TfidfVectorizer()],\n",
    "    \"preprocessor__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "    \"preprocessor__min_df\": [2, 4, 7, 10],\n",
    "    \"preprocessor__stop_words\":['english'],\n",
    "    'model': [LogisticRegression()],\n",
    "    'model__penalty': ['l1', 'l2'],\n",
    "    'model__max_iter': [1000],\n",
    "    'model__C': np.logspace(-4, 4, 10)\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"preprocessor\", None),\n",
    "    (\"model\", None)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(pipe, grid, n_jobs=-1, cv=3, verbose=2, n_iter=10, scoring=\"f1_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('preprocessor', None),\n",
       "                                             ('model', None)]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions=[{'model': [LogisticRegression()],\n",
       "                                         'model__C': array([1.00000000e-04, 7.74263683e-04, 5.99484250e-03, 4.64158883e-02,\n",
       "       3.59381366e-01, 2.78255940e+00, 2.15443469e+01, 1.66810054e+02,\n",
       "       1.29154967e+03, 1.00000000e+04]),\n",
       "                                         'model__max_iter': [1000],\n",
       "                                         'mo...\n",
       "       3.59381366e-01, 2.78255940e+00, 2.15443469e+01, 1.66810054e+02,\n",
       "       1.29154967e+03, 1.00000000e+04]),\n",
       "                                         'model__max_iter': [1000],\n",
       "                                         'model__penalty': ['l1', 'l2'],\n",
       "                                         'preprocessor': [TfidfVectorizer(min_df=2,\n",
       "                                                                          ngram_range=(1,\n",
       "                                                                                       2),\n",
       "                                                                          stop_words='english')],\n",
       "                                         'preprocessor__min_df': [2, 4, 7, 10],\n",
       "                                         'preprocessor__ngram_range': [(1, 1),\n",
       "                                                                       (1, 2),\n",
       "                                                                       (1, 3)],\n",
       "                                         'preprocessor__stop_words': ['english']}],\n",
       "                   scoring='f1_weighted', verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(data_dict[\"data\"], data_dict[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 TfidfVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                                 stop_words='english')),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=166.81005372000558, max_iter=1000))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117377807076205"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = fetch_20newsgroups(subset=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 TfidfVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                                 stop_words='english')),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=166.81005372000558, max_iter=1000))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = search.best_estimator_\n",
    "est.fit(data_dict['data'], data_dict['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82       319\n",
      "           1       0.72      0.83      0.77       389\n",
      "           2       0.78      0.74      0.76       394\n",
      "           3       0.70      0.75      0.73       392\n",
      "           4       0.82      0.85      0.83       385\n",
      "           5       0.85      0.75      0.80       395\n",
      "           6       0.80      0.91      0.85       390\n",
      "           7       0.91      0.90      0.90       396\n",
      "           8       0.96      0.96      0.96       398\n",
      "           9       0.90      0.94      0.92       397\n",
      "          10       0.97      0.97      0.97       399\n",
      "          11       0.95      0.91      0.93       396\n",
      "          12       0.79      0.79      0.79       393\n",
      "          13       0.90      0.85      0.88       396\n",
      "          14       0.91      0.92      0.92       394\n",
      "          15       0.88      0.93      0.91       398\n",
      "          16       0.78      0.91      0.84       364\n",
      "          17       0.97      0.89      0.93       376\n",
      "          18       0.83      0.65      0.73       310\n",
      "          19       0.76      0.67      0.71       251\n",
      "\n",
      "    accuracy                           0.85      7532\n",
      "   macro avg       0.85      0.85      0.85      7532\n",
      "weighted avg       0.85      0.85      0.85      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "pred = est.predict(test['data'])\n",
    "print(metrics.classification_report(test['target'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal-rd-course",
   "language": "python",
   "name": "personal-rd-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
